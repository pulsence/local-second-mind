# Todo

## General
- Do research on particular models for particular tasks, for example using transformers directly
- Look into how to run models in app
- Explore multimodal capabilities (images, audio via Whisper)
- Create CLAUDE.md to enforce code/plan conventions

## Infrastructure
- Add some kind of GUI over tooling (TUI with Textual or Web UI)
- Complete remaining documentation stubs (see docs/ folder)
- When reading config query.modes these modes should add to existing built-in modes,
or be merged with built-in modes
- Create installers
- Provider modules should have submodules for:
    - db (with providers for chroma and psql)
    - ai (with providers for the different ai providers)
    - remote (with providers for the different remote apis like brave, wikimedia, etc.)
- Check to make sure there is not unnecessary duplicated code
- Check for places to improve error handling and fault resilience

## Testing 
- test module structure should match the code module structure
- Run full pytest suite and verify all tests pass
- Create synthetic test data to run intergration tests

## Ingest
- Add embeddings model selection (allow user to choose different embedding models)
- Add language detection and tagging for multilingual corpora
- Add option to machine translate chunks (for cross-language search)
- Consider version control for chunks (track document evolution over time)
- Enable root folders in config to be tagged to aid in identifying the kind of content in folders
- Enable tagging by folder of chunks
- Still getting MuPDF error: library error: zlib error: incorrect header check
- Store page number as best able of chunks and then when a chunk is cited
or shown, include the page number
- Chunk based upon internal document structure, meaning don't include
different sections in the same chunk. Keeping heading levels in same chunk
or a chunk should not span two heading levels.

## Query
- Complete remaining documentation for query modes, notes, remote sources
- Add more remote source providers (Wikipedia, ArXiv, custom APIs)
- Add cost tracking and budgeting for LLM API calls
- Implement streaming responses for better UX on long synthesis
- Add export citations to BibTeX/Zotero format
- Integration with note-taking apps (Obsidian, Logseq)
- Impliment query caching to be efficient in call usage

## Remote Providers
- Figure out natural word processing for arvix

## Multi-Provider Support
- Check the implimentations of the ai providers and see if the base
BaseLLMProvider could not encapsulate the functionality or if it should
be moved into some kind of helper.

## Advanced Features (Future)
- Multi-hop reasoning for research mode
- Performance benchmarks and optimization
- Collaborative features (shared knowledge bases)
- Support for larger collections (100K+ chunks with sharding strategies)
