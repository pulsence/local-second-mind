# Todo

## General
- Do research on particular models for particular tasks, for example using transformers directly
- Look into how to run models in app
- Explore multimodal capabilities (images, audio via Whisper)

## Infrastructure
- Add some kind of GUI over tooling (TUI with Textual or Web UI)
- Complete remaining documentation stubs (see docs/ folder)
- Run full pytest suite and verify all tests pass

## Ingest
- Add embeddings model selection (allow user to choose different embedding models)
- Add language detection and tagging for multilingual corpora
- Add option to machine translate chunks (for cross-language search)
- Consider version control for chunks (track document evolution over time)

## Query
- Complete remaining documentation for query modes, notes, remote sources
- Add more remote source providers (Wikipedia, ArXiv, custom APIs)
- Add cost tracking and budgeting for LLM API calls
- Implement streaming responses for better UX on long synthesis
- Add export citations to BibTeX/Zotero format
- Integration with note-taking apps (Obsidian, Logseq)

## Multi-Provider Support
- Implement Anthropic Claude provider (template ready in docs/api-reference/ADDING_PROVIDERS.md)
- Implement local model support (via Ollama or llama.cpp)
- Implement Azure OpenAI provider
- Add provider health checks and status monitoring

## Advanced Features (Future)
- Multi-hop reasoning for research mode
- Performance benchmarks and optimization
- Collaborative features (shared knowledge bases)
- Support for larger collections (100K+ chunks with sharding strategies)
