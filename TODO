# Todo

## General
- Do research on particular models for particular tasks, for example using transformers directly
- Look into how to run models in app
- Explore multimodal capabilities (images, audio via Whisper)
- Create CLAUDE.md to enforce code/plan conventions

## Infrastructure
- Add some kind of GUI over tooling (TUI with Textual or Web UI)
- Complete remaining documentation stubs (see docs/ folder)
- When reading config query.modes these modes should add to existing built-in modes,
or be merged with built-in modes
- Create installers
- Provider modules should have submodules for:
    - db (with providers for chroma and psql)
    - ai (with providers for the different ai providers)
    - remote (with providers for the different remote apis like brave, wikimedia, etc.)
- Check to make sure there is not unnecessary duplicated code
- Check for places to improve error handling and fault resilience
- Check for files that are quite large and how they can be intelligently split into sub-modules
- Remove all legacy and depracted code paths
- models.py needs to be split apart
- Look for places to lazy load modules to improve start time
- The global default folder for this project when one is not specified should be
at `<USER_FOLDER>/Local Second Mind/`. Whenever relative folder paths for data files (e.g., notes, chats, etc.) are
used, it should be assumed to be relative to this project folder.
- The user should be able to set this global folder in the config.

## Testing 
- test module structure should match the code module structure
- Run full pytest suite and verify all tests pass
- Create synthetic test data to run intergration tests

## Ingest
- Add embeddings model selection (allow user to choose different embedding models)
- Add language detection and tagging for multilingual corpora
- Add option to machine translate chunks (for cross-language search)
- Consider version control for chunks (track document evolution over time)
- Enable root folders in config to be tagged to aid in identifying the kind of content in folders
- Enable tagging by folder of chunks
- Still getting MuPDF error: library error: zlib error: incorrect header check
- Store page number as best able of chunks and then when a chunk is cited
or shown, include the page number
- Chunk based upon internal document structure, meaning don't include
different sections in the same chunk. Keeping heading levels in same chunk
or a chunk should not span two heading levels.
- Enable partial ingest by time and file count

## Query
- Complete remaining documentation for query modes, notes, remote sources
- Add more remote source providers (Wikipedia, ArXiv, custom APIs)
- Add cost tracking and budgeting for LLM API calls
- Implement streaming responses for better UX on long synthesis
- Add export citations to BibTeX/Zotero format
- Integration with note-taking apps (Obsidian, Logseq)
- Impliment query caching to be efficient in call usage
- Create a way to turn natural language into API calls.
    - There should be an "intelligent" deterministic way
    - There should also be an AI provider way
- Query chat modes: Chat or Single-shot
- There should be a global setting for chats that sets chat saving parameters.
The default save location shold be `<GLOBAL_FOLDER/Chats/`
- Query modes can then adjust this save location, or if automatic saves happen.
- Notes settings should be set gloabl in the config not per mode. 
- Notes should default to `<GLOBAL_FOLDER/Notes/` when none is set.
- Query modes can then set subfolder locations in the global notes
folder and other parameters

## Modes and Agents
- Multi-hop reasoning for research mode
- Research into creating agents. Right now "modes" are like what other call agents,
but really "modes" in LSM are configurations on building particular contexts. An
agent will be a "mini-program" or "sub-routine" that can chain multiple modes
or act upon responses to the produce further responses. And so a "mode" results
in a single response. An agent can result in multiple response and even other
results like the production of artifacts (e.g., files) and modifications of
the users system itself (in theory).
- Provide ability to chain providers together in a meta-provider when the subproviders act a inputs
to later providers and then the whole meta-provider becomes a source for query. Sources need to
be maintained throughout the meta-provider
- Create OpenAlex - Crossref - Unpaywall - CORE pipeline to find, download, and ingest documents

## Remote Source Providers
- Look into AI Providers Web Search API as alts to Brave
- Perseus CTS API
- Digital Public Library of America (DPLA) API
- Library of Congress (loc.gov) JSON/YAML API
- Smithsonian Open Access API
- The Met Collection API (Open Access)
- Rijksmuseum data services
- IIIF APIs (Image / Presentation / Content Search
- Wikidata SPARQL endpoint
- PubMed/PubMed Central
- SSRN (Social Science Research Network)
- PhilArchive
- Project MUSE (humanities)
- News Sources: NYTimes, et al.
- Social Media: Twitter, et al.
- Classical Language Text Sources:
    - https://github.com/OpenGreekAndLatin/patrologia_latina-dev
    - https://github.com/OpenGreekAndLatin/csel-dev
    - https://github.com/OpenGreekAndLatin/First1KGreek
    - https://github.com/OpenGreekAndLatin
    - https://www.corpusthomisticum.org/

## AI Provider Support
- Check the implimentations of the ai providers and see if the base
BaseLLMProvider could not encapsulate the functionality or if it should
be moved into some kind of helper.

## Advanced Features
- Collaborative features (shared knowledge bases)
- Support for larger collections (100K+ chunks with sharding strategies)
